{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Aproximate-nearest-neighbor-search.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "t14FGU9bKoMX"
      },
      "source": [
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLDOLyExkjLV",
        "outputId": "9756302d-9dff-4352-dad3-511c9f65b91b"
      },
      "source": [
        "!pip install faiss-gpu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faiss-gpu in /usr/local/lib/python3.7/dist-packages (1.7.1.post2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7p3eypTUftN6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d99f550b-84e8-4ff9-af9e-8b5e4cc8a44e"
      },
      "source": [
        "def movies_data_load():\n",
        "    with open('movies.pickle', 'rb') as f:\n",
        "        movies = pickle.load(f)\n",
        "    return movies\n",
        "\n",
        "movies_data = movies_data_load()\n",
        "movies_vector = movies_data[\"vector\"]\n",
        "movies_names = movies_data[\"name\"]\n",
        "movies_data"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': array(['Toy Story (1995)', 'GoldenEye (1995)', 'Four Rooms (1995)', ...,\n",
              "        'Sliding Doors (1998)', 'You So Crazy (1994)',\n",
              "        'Scream of Stone (Schrei aus Stein) (1991)'], dtype=object),\n",
              " 'vector': array([[-0.01780608, -0.14265831,  0.10308606, ...,  0.09659795,\n",
              "         -0.17529577, -0.03061521],\n",
              "        [-0.03357764,  0.16418771,  0.21801303, ...,  0.16502103,\n",
              "         -0.09166156,  0.05047869],\n",
              "        [-0.2761452 , -0.01991325, -0.04969981, ...,  0.0258275 ,\n",
              "         -0.08328608, -0.0152858 ],\n",
              "        ...,\n",
              "        [ 0.05142734, -0.01683608, -0.20441587, ...,  0.00045828,\n",
              "          0.14679626,  0.2462584 ],\n",
              "        [ 0.04491899, -0.02819411, -0.09472758, ..., -0.02152078,\n",
              "          0.16223577,  0.19897607],\n",
              "        [ 0.02531924,  0.03099714,  0.06437534, ..., -0.07260127,\n",
              "          0.0467432 ,  0.07893164]], dtype=float32)}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9NftjNpgEYF",
        "outputId": "bc10c17d-2531-4e67-a416-ef6c0a5e626d"
      },
      "source": [
        "import faiss\n",
        "faiss.MatrixStats(movies_vector).comments.split(\"\\n\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['analyzing 1682 vectors of size 64',\n",
              " 'no NaN or Infs in data',\n",
              " 'all vectors are distinct',\n",
              " 'range of L2 norms=[0.747558, 1.80436] (0 null vectors)',\n",
              " 'matrix contains no 0s',\n",
              " 'no constant dimensions',\n",
              " 'no dimension has a too large mean',\n",
              " 'stddevs per dimension are in [0.112036 0.158214]',\n",
              " '']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnak8t0TgIl9"
      },
      "source": [
        "movie_index = faiss.IndexFlatL2(movies_vector.shape[1])\n",
        "movie_index.add(movies_vector)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6qNuuT0gKZH"
      },
      "source": [
        "movies_search_vector = movies_vector[90:91]\n",
        "distances, indices = movie_index.search(movies_search_vector, 10)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqaEXvLigMVv",
        "outputId": "579a15f0-fc5f-4ef7-dd96-360475f143b7"
      },
      "source": [
        "print(f\"Similar movie to {movies_names[90]} are:\\n\")\n",
        "print([movies_names[j] for j in indices[0]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similar movie to Nightmare Before Christmas, The (1993) are:\n",
            "\n",
            "['Nightmare Before Christmas, The (1993)', 'Heavy Metal (1981)', 'Sirens (1994)', 'Beauty and the Beast (1991)', 'Akira (1988)', 'Fantasia (1940)', 'Benny & Joon (1993)', 'Barbarella (1968)', \"Pete's Dragon (1977)\", 'James and the Giant Peach (1996)']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0JlfjgQ0MME"
      },
      "source": [
        "### Exaustive Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUQtgUCPgPFF"
      },
      "source": [
        "exaustive_quantizer = faiss.IndexFlatL2(movies_vector.shape[1])\n",
        "exaustive_index = faiss.IndexIVFFlat(exaustive_quantizer, \n",
        "                           movies_vector.shape[1], \n",
        "                           100,             \n",
        "                           8)               \n",
        "exaustive_index.train(movies_vector)\n",
        "exaustive_index.add(movies_vector)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxUB8esEgTJo"
      },
      "source": [
        "exaustive_search_vector = movies_vector[90:91]\n",
        "distances, indices = movie_index.search(movies_search_vector, 10)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7WXU1uJgZS3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "343fa452-7845-442d-ce54-aa75e891c2b7"
      },
      "source": [
        "print(f\"Similar moview to {movies_names[90]} are:\\n\")\n",
        "print([movies_names[i] for i in indices[0]])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similar moview to Nightmare Before Christmas, The (1993) are:\n",
            "\n",
            "['Nightmare Before Christmas, The (1993)', 'Heavy Metal (1981)', 'Sirens (1994)', 'Beauty and the Beast (1991)', 'Akira (1988)', 'Fantasia (1940)', 'Benny & Joon (1993)', 'Barbarella (1968)', \"Pete's Dragon (1977)\", 'James and the Giant Peach (1996)']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j77ZUwlRzGG_"
      },
      "source": [
        "### Product Quantization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIHnDsfVlC_8"
      },
      "source": [
        "product_quantizer = faiss.IndexFlatL2(movies_vector.shape[1])\n",
        "product_index = faiss.IndexIVFPQ(product_quantizer, \n",
        "                         movies_vector.shape[1], \n",
        "                         100,             \n",
        "                         8,                \n",
        "                         8)               \n",
        "product_index.train(movies_vector)\n",
        "product_index.add(movies_vector)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ue93xHgilG9Q"
      },
      "source": [
        "product_quantization_search_vector = movies_vector[90:91]\n",
        "distances, indices = product_index.search(product_quantization_search_vector, 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oskJbhblJFh",
        "outputId": "254f490d-200e-4411-fc78-74007696a203"
      },
      "source": [
        "print(f\"Similar moview to {movies_names[90]} are:\\n\")\n",
        "print([movies_names[k] for k in indices[0]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similar moview to Nightmare Before Christmas, The (1993) are:\n",
            "\n",
            "['Nightmare Before Christmas, The (1993)', 'Heavy Metal (1981)', 'Pink Floyd - The Wall (1982)', 'Akira (1988)', 'Hamlet (1996)', 'Full Metal Jacket (1987)', 'Supercop (1992)', 'Scream of Stone (Schrei aus Stein) (1991)', 'Scream of Stone (Schrei aus Stein) (1991)', 'Scream of Stone (Schrei aus Stein) (1991)']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNcclY7cq4Gl"
      },
      "source": [
        "### Trees and Forests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q614wH-mlLp5",
        "outputId": "720b3abe-2c54-4ead-bb99-d530a0160712"
      },
      "source": [
        "!pip install apache_beam\n",
        "!pip install 'scikit_learn~=0.23.0'  # For gaussian_random_matrix.\n",
        "!pip install annoy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting apache_beam\n",
            "  Downloading apache_beam-2.34.0-cp37-cp37m-manylinux2010_x86_64.whl (9.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.8 MB 7.4 MB/s \n",
            "\u001b[?25hCollecting fastavro<2,>=0.21.4\n",
            "  Downloading fastavro-1.4.7-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 56.5 MB/s \n",
            "\u001b[?25hCollecting future<1.0.0,>=0.18.2\n",
            "  Downloading future-0.18.2.tar.gz (829 kB)\n",
            "\u001b[K     |████████████████████████████████| 829 kB 55.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2018.3 in /usr/local/lib/python3.7/dist-packages (from apache_beam) (2018.9)\n",
            "Collecting hdfs<3.0.0,>=2.1.0\n",
            "  Downloading hdfs-2.6.0-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: httplib2<0.20.0,>=0.8 in /usr/local/lib/python3.7/dist-packages (from apache_beam) (0.17.4)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from apache_beam) (2.8.2)\n",
            "Requirement already satisfied: grpcio<2,>=1.29.0 in /usr/local/lib/python3.7/dist-packages (from apache_beam) (1.42.0)\n",
            "Collecting dill<0.3.2,>=0.3.1.1\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "\u001b[K     |████████████████████████████████| 151 kB 61.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions<4,>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from apache_beam) (3.10.0.2)\n",
            "Requirement already satisfied: pyarrow<6.0.0,>=0.15.1 in /usr/local/lib/python3.7/dist-packages (from apache_beam) (3.0.0)\n",
            "Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from apache_beam) (3.12.1)\n",
            "Requirement already satisfied: numpy<1.21.0,>=1.14.3 in /usr/local/lib/python3.7/dist-packages (from apache_beam) (1.19.5)\n",
            "Collecting avro-python3!=1.9.2,<1.10.0,>=1.8.1\n",
            "  Downloading avro-python3-1.9.2.1.tar.gz (37 kB)\n",
            "Collecting requests<3.0.0,>=2.24.0\n",
            "  Downloading requests-2.26.0-py2.py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 804 kB/s \n",
            "\u001b[?25hRequirement already satisfied: oauth2client<5,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from apache_beam) (4.1.3)\n",
            "Collecting orjson<4.0\n",
            "  Downloading orjson-3.6.4-cp37-cp37m-manylinux_2_24_x86_64.whl (249 kB)\n",
            "\u001b[K     |████████████████████████████████| 249 kB 68.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf<4,>=3.12.2 in /usr/local/lib/python3.7/dist-packages (from apache_beam) (3.17.3)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache_beam) (1.3.0)\n",
            "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache_beam) (1.7)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio<2,>=1.29.0->apache_beam) (1.15.0)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from hdfs<3.0.0,>=2.1.0->apache_beam) (0.6.2)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from oauth2client<5,>=2.0.1->apache_beam) (0.4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from oauth2client<5,>=2.0.1->apache_beam) (0.2.8)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from oauth2client<5,>=2.0.1->apache_beam) (4.7.2)\n",
            "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.7/dist-packages (from pydot<2,>=1.2.0->apache_beam) (3.0.6)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->apache_beam) (2.0.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->apache_beam) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->apache_beam) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->apache_beam) (2021.10.8)\n",
            "Building wheels for collected packages: avro-python3, dill, future\n",
            "  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for avro-python3: filename=avro_python3-1.9.2.1-py3-none-any.whl size=43512 sha256=4c8bcaf9185095028f7c5f669dde9369692648bc3992f7a699366a5abf436267\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/49/5f/fdb5b9d85055c478213e0158ac122b596816149a02d82e0ab1\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78546 sha256=6122d62a5c6437f745e9b9ab5364f69adab4416a1b96a3519d75284a9d6d4537\n",
            "  Stored in directory: /root/.cache/pip/wheels/a4/61/fd/c57e374e580aa78a45ed78d5859b3a44436af17e22ca53284f\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=b085f21f8363a0a8138765b3a35f088b85a76335b585eb32b41f1e387410b39c\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
            "Successfully built avro-python3 dill future\n",
            "Installing collected packages: requests, orjson, hdfs, future, fastavro, dill, avro-python3, apache-beam\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: future\n",
            "    Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.4\n",
            "    Uninstalling dill-0.3.4:\n",
            "      Successfully uninstalled dill-0.3.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "multiprocess 0.70.12.2 requires dill>=0.3.4, but you have dill 0.3.1.1 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas~=1.1.0; python_version >= \"3.0\", but you have pandas 1.3.4 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.26.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed apache-beam-2.34.0 avro-python3-1.9.2.1 dill-0.3.1.1 fastavro-1.4.7 future-0.18.2 hdfs-2.6.0 orjson-3.6.4 requests-2.26.0\n",
            "Collecting scikit_learn~=0.23.0\n",
            "  Downloading scikit_learn-0.23.2-cp37-cp37m-manylinux1_x86_64.whl (6.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8 MB 8.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit_learn~=0.23.0) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit_learn~=0.23.0) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit_learn~=0.23.0) (3.0.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit_learn~=0.23.0) (1.19.5)\n",
            "Installing collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.1\n",
            "    Uninstalling scikit-learn-1.0.1:\n",
            "      Successfully uninstalled scikit-learn-1.0.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.23.2 which is incompatible.\u001b[0m\n",
            "Successfully installed scikit-learn-0.23.2\n",
            "Collecting annoy\n",
            "  Downloading annoy-1.17.0.tar.gz (646 kB)\n",
            "\u001b[K     |████████████████████████████████| 646 kB 8.4 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: annoy\n",
            "  Building wheel for annoy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for annoy: filename=annoy-1.17.0-cp37-cp37m-linux_x86_64.whl size=391674 sha256=bc0a6b3cc337b79d1997fa8475f9f8b366043b9c3c4548d6ddff15b944cd7e2e\n",
            "  Stored in directory: /root/.cache/pip/wheels/4f/e8/1e/7cc9ebbfa87a3b9f8ba79408d4d31831d67eea918b679a4c07\n",
            "Successfully built annoy\n",
            "Installing collected packages: annoy\n",
            "Successfully installed annoy-1.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VWahlPKlcsM"
      },
      "source": [
        "import annoy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t70rqLn4lew_",
        "outputId": "f2447dfb-0cca-4907-ea57-a1a693496445"
      },
      "source": [
        "def load_annoy_data():\n",
        "    with open('movies.pickle', 'rb') as f:\n",
        "        annoy_data = pickle.load(f)\n",
        "    return annoy_data\n",
        "\n",
        "annoy_data = load_annoy_data()\n",
        "annoy_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': array(['Toy Story (1995)', 'GoldenEye (1995)', 'Four Rooms (1995)', ...,\n",
              "        'Sliding Doors (1998)', 'You So Crazy (1994)',\n",
              "        'Scream of Stone (Schrei aus Stein) (1991)'], dtype=object),\n",
              " 'vector': array([[-0.01780608, -0.14265831,  0.10308606, ...,  0.09659795,\n",
              "         -0.17529577, -0.03061521],\n",
              "        [-0.03357764,  0.16418771,  0.21801303, ...,  0.16502103,\n",
              "         -0.09166156,  0.05047869],\n",
              "        [-0.2761452 , -0.01991325, -0.04969981, ...,  0.0258275 ,\n",
              "         -0.08328608, -0.0152858 ],\n",
              "        ...,\n",
              "        [ 0.05142734, -0.01683608, -0.20441587, ...,  0.00045828,\n",
              "          0.14679626,  0.2462584 ],\n",
              "        [ 0.04491899, -0.02819411, -0.09472758, ..., -0.02152078,\n",
              "          0.16223577,  0.19897607],\n",
              "        [ 0.02531924,  0.03099714,  0.06437534, ..., -0.07260127,\n",
              "          0.0467432 ,  0.07893164]], dtype=float32)}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouN_JCV4lkh2"
      },
      "source": [
        "class tree_index():\n",
        "    def __init__(self, annoy_vectors, tree_labels):\n",
        "        self.dimention = annoy_vectors.shape[1]\n",
        "        self.annoy_vectors = annoy_vectors.astype('float32')\n",
        "        self.tree_labels = tree_labels\n",
        "\n",
        "\n",
        "    def build(self, total_trees=5):\n",
        "        self.index = annoy.AnnoyIndex(self.dimention)\n",
        "        for i, vec in enumerate(self.annoy_vectors):\n",
        "            self.index.add_item(i, vec.tolist())\n",
        "        self.index.build(total_trees)\n",
        "        \n",
        "    def query(self, vector, k=11):\n",
        "        indices = self.index.get_nns_by_vector(vector.tolist(), k)\n",
        "        return [self.tree_labels[l] for l in indices]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npwQvp1QlnE0",
        "outputId": "f8906133-48f9-4cf6-c1f4-70ea071fbd80"
      },
      "source": [
        "tree_vector_index = tree_index(annoy_data[\"vector\"], annoy_data[\"name\"])\n",
        "tree_vector_index.build()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: FutureWarning: The default argument for metric will be removed in future version of Annoy. Please pass metric='angular' explicitly.\n",
            "  if __name__ == '__main__':\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJpPZM7vlpQz",
        "outputId": "ed18c090-ec3c-436f-8298-60823c901ce7"
      },
      "source": [
        "movie_annoy_vector, name_of_movie = annoy_data['vector'][90], annoy_data['name'][90]\n",
        "same_movies = '\\n* '.join(tree_vector_index.query(movie_annoy_vector))\n",
        "print(f\"Similar moview to {name_of_movie} are:\\n* {same_movies}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similar moview to Nightmare Before Christmas, The (1993) are:\n",
            "* Nightmare Before Christmas, The (1993)\n",
            "* Aladdin (1992)\n",
            "* Blade Runner (1982)\n",
            "* Aliens (1986)\n",
            "* Pink Floyd - The Wall (1982)\n",
            "* Brazil (1985)\n",
            "* Wrong Trousers, The (1993)\n",
            "* Alien (1979)\n",
            "* Return of the Jedi (1983)\n",
            "* E.T. the Extra-Terrestrial (1982)\n",
            "* Grand Day Out, A (1992)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBItp9bWrjLC"
      },
      "source": [
        "### HNSW"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxQeR1gcls_P",
        "outputId": "1d5c67b9-78b5-4574-fe49-c8cd0477885c"
      },
      "source": [
        "!pip install nmslib"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nmslib\n",
            "  Downloading nmslib-2.1.1-cp37-cp37m-manylinux2010_x86_64.whl (13.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 13.5 MB 8.2 MB/s \n",
            "\u001b[?25hCollecting pybind11<2.6.2\n",
            "  Downloading pybind11-2.6.1-py2.py3-none-any.whl (188 kB)\n",
            "\u001b[K     |████████████████████████████████| 188 kB 61.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from nmslib) (5.4.8)\n",
            "Requirement already satisfied: numpy>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from nmslib) (1.19.5)\n",
            "Installing collected packages: pybind11, nmslib\n",
            "Successfully installed nmslib-2.1.1 pybind11-2.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1ChHOQolvOs"
      },
      "source": [
        "import nmslib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pg44wpilxQx",
        "outputId": "a1c7b82b-c5b3-4ddf-f8d7-1d61f77cf915"
      },
      "source": [
        "def load_graph_data():\n",
        "    with open('movies.pickle', 'rb') as f:\n",
        "        graph_data = pickle.load(f)\n",
        "    return graph_data\n",
        "\n",
        "graph_data = load_graph_data()\n",
        "graph_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': array(['Toy Story (1995)', 'GoldenEye (1995)', 'Four Rooms (1995)', ...,\n",
              "        'Sliding Doors (1998)', 'You So Crazy (1994)',\n",
              "        'Scream of Stone (Schrei aus Stein) (1991)'], dtype=object),\n",
              " 'vector': array([[-0.01780608, -0.14265831,  0.10308606, ...,  0.09659795,\n",
              "         -0.17529577, -0.03061521],\n",
              "        [-0.03357764,  0.16418771,  0.21801303, ...,  0.16502103,\n",
              "         -0.09166156,  0.05047869],\n",
              "        [-0.2761452 , -0.01991325, -0.04969981, ...,  0.0258275 ,\n",
              "         -0.08328608, -0.0152858 ],\n",
              "        ...,\n",
              "        [ 0.05142734, -0.01683608, -0.20441587, ...,  0.00045828,\n",
              "          0.14679626,  0.2462584 ],\n",
              "        [ 0.04491899, -0.02819411, -0.09472758, ..., -0.02152078,\n",
              "          0.16223577,  0.19897607],\n",
              "        [ 0.02531924,  0.03099714,  0.06437534, ..., -0.07260127,\n",
              "          0.0467432 ,  0.07893164]], dtype=float32)}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1RklhFbl3g6"
      },
      "source": [
        "class hnsw_index():\n",
        "    def __init__(self, vectors, labels):\n",
        "        self.dimention = vectors.shape[1]\n",
        "        self.vectors = vectors.astype('float32')\n",
        "        self.labels = labels\n",
        "\n",
        "    def build(self):\n",
        "        self.index = nmslib.init(method='hnsw', space='cosinesimil')\n",
        "        self.index.addDataPointBatch(self.vectors)\n",
        "        self.index.createIndex({'post': 2})\n",
        "        \n",
        "    def query(self, vector, k=10):\n",
        "        indices = self.index.knnQuery(vector, k=k)\n",
        "        return [self.labels[z] for z in indices[0]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZ3xHayrl6SI"
      },
      "source": [
        "graph_hnsw_index = hnsw_index(graph_data[\"vector\"], graph_data[\"name\"])\n",
        "graph_hnsw_index.build()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hjveoDjl8nZ",
        "outputId": "32205128-7795-48bc-aa73-cd491c90bc3b"
      },
      "source": [
        "graph_movie_vector, namee_of_movie = graph_data['vector'][90], graph_data['name'][90]\n",
        "same_shows = '\\n* '.join(graph_hnsw_index.query(graph_movie_vector))\n",
        "print(f\"Similar moview to {namee_of_movie} are:\\n* {same_shows}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similar moview to Nightmare Before Christmas, The (1993) are:\n",
            "* Nightmare Before Christmas, The (1993)\n",
            "* Beauty and the Beast (1991)\n",
            "* Fantasia (1940)\n",
            "* Heavy Metal (1981)\n",
            "* Aladdin (1992)\n",
            "* Snow White and the Seven Dwarfs (1937)\n",
            "* Batman (1989)\n",
            "* James and the Giant Peach (1996)\n",
            "* Blade Runner (1982)\n",
            "* Aliens (1986)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1ELg2zqxevo"
      },
      "source": [
        "### LSH"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjF_5cbcI6vg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bcbcf99-4bf5-441b-c934-351a07766dfc"
      },
      "source": [
        "def load_lsh_data():\n",
        "    with open('movies.pickle', 'rb') as f:\n",
        "        lsh_data = pickle.load(f)\n",
        "    return lsh_data\n",
        "\n",
        "lsh_data = load_lsh_data()\n",
        "lsh_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': array(['Toy Story (1995)', 'GoldenEye (1995)', 'Four Rooms (1995)', ...,\n",
              "        'Sliding Doors (1998)', 'You So Crazy (1994)',\n",
              "        'Scream of Stone (Schrei aus Stein) (1991)'], dtype=object),\n",
              " 'vector': array([[-0.01780608, -0.14265831,  0.10308606, ...,  0.09659795,\n",
              "         -0.17529577, -0.03061521],\n",
              "        [-0.03357764,  0.16418771,  0.21801303, ...,  0.16502103,\n",
              "         -0.09166156,  0.05047869],\n",
              "        [-0.2761452 , -0.01991325, -0.04969981, ...,  0.0258275 ,\n",
              "         -0.08328608, -0.0152858 ],\n",
              "        ...,\n",
              "        [ 0.05142734, -0.01683608, -0.20441587, ...,  0.00045828,\n",
              "          0.14679626,  0.2462584 ],\n",
              "        [ 0.04491899, -0.02819411, -0.09472758, ..., -0.02152078,\n",
              "          0.16223577,  0.19897607],\n",
              "        [ 0.02531924,  0.03099714,  0.06437534, ..., -0.07260127,\n",
              "          0.0467432 ,  0.07893164]], dtype=float32)}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnuuO7I3l_7C"
      },
      "source": [
        "class lsh():\n",
        "    def __init__(self, vectors, labels):\n",
        "        self.dimention = vectors.shape[1]\n",
        "        self.vectors = vectors.astype('float32')\n",
        "        self.labels = labels\n",
        "\n",
        "\n",
        "    def build(self, number_of_partition=8, search_in_x_partitions=2, subvector_size=8):\n",
        "        lsh_quantizer = faiss.IndexFlatL2(self.dimention)\n",
        "        self.lsh_index = faiss.IndexIVFPQ(lsh_quantizer, self.dimention, number_of_partition, search_in_x_partitions, subvector_size)\n",
        "        self.lsh_index.train(self.vectors)\n",
        "        self.lsh_index.add(self.vectors)\n",
        "        \n",
        "    def query(self, vectors, k=10):\n",
        "        distances, indices = self.lsh_index.search(vectors, k) \n",
        "        return [self.labels[a] for a in indices[0]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGVdXU9tmCe_"
      },
      "source": [
        "lsh_index = lsh(lsh_data[\"vector\"], lsh_data[\"name\"])\n",
        "lsh_index.build()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3oCu2_lmEeU",
        "outputId": "5b8e3c99-fd8d-47d5-8caf-74cf34b508e8"
      },
      "source": [
        "lsh_vector, name_of_movie = lsh_data['vector'][90:91], lsh_data['name'][90]\n",
        "same_movies = '\\n* '.join(lsh_index.query(lsh_vector))\n",
        "print(f\"Similar moview to {name_of_movie} are:\\n* {same_movies}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similar moview to Nightmare Before Christmas, The (1993) are:\n",
            "* Nightmare Before Christmas, The (1993)\n",
            "* Fantasia (1940)\n",
            "* Brazil (1985)\n",
            "* Monty Python's Life of Brian (1979)\n",
            "* This Is Spinal Tap (1984)\n",
            "* Hunt for Red October, The (1990)\n",
            "* Sneakers (1992)\n",
            "* Lion King, The (1994)\n",
            "* Clockwork Orange, A (1971)\n",
            "* Full Metal Jacket (1987)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBoKJv1fJzE7"
      },
      "source": [
        "**References:**\n",
        "\n",
        "- https://towardsdatascience.com/comprehensive-guide-to-approximate-nearest-neighbors-algorithms-8b94f057d6b6\n",
        "\n",
        "- https://github.com/eyaltrabelsi/my-notebooks/tree/87d4727e777bec04fee89553e4bc83fad7294c8a/Lectures/search_in_practice-approximate_nearest_neighbors"
      ]
    }
  ]
}